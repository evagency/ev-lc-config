version: 1.1.6

cache: true

# INTERFACE CUSTOMIZATION
interface:
  privacyPolicy:
    externalUrl: "https://librechat.ai/privacy-policy"
    openNewTab: true
  termsOfService:
    externalUrl: "https://librechat.ai/tos"
    openNewTab: true

registration:
  # Available: ["discord", "facebook", "github", "google", "openid"]
  socialLogins: ["google"]

# FILE CONFIGURATION
fileConfig:
  endpoints:
    assistants:
      fileLimit: 5
      fileSizeLimit: 30 # Maximum size for an individual file in MB
      totalSizeLimit: 50 # Maximum total size for all files in a single request in MB
      supportedMimeTypes:
        - "image/.*"
        - "application/pdf"
        - "application/json"
        - "application/xml"
        - "application/yaml"
        - "text/plain"
        - "text/markdown"
        - "text/csv"
        - "application/msword"
        - "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
        - "application/vnd.ms-excel"
        - "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        - "application/vnd.ms-powerpoint"
        - "application/vnd.openxmlformats-officedocument.presentationml.presentation"
        - "application/vnd.google-apps.document"
        - "application/vnd.google-apps.spreadsheet"
        - "application/vnd.google-apps.presentation"
        - "application/vnd.google-apps.fusiontable"
        - "application/vnd.google-apps.drawing"
        - "application/vnd.google-apps.audio"
    openAI:
      disabled: false # Disables file uploading to the OpenAI endpoint
    default:
      totalSizeLimit: 20

# RATE LIMITING
rateLimits:
  fileUploads:
    ipMax: 100
    ipWindowInMinutes: 60 # Rate limit window for file uploads per IP
    userMax: 50
    userWindowInMinutes: 60 # Rate limit window for file uploads per user

# CUSTOM ENDPOINTS
endpoints:
  assistants:
    disableBuilder: false # Disable Assistants Builder Interface by setting to `true`
    pollIntervalMs: 750 # Polling interval for checking assistant updates
    timeoutMs: 180000 # Timeout for assistant operations
    # Should only be one or the other, either `supportedIds` or `excludedIds`
    # supportedIds: [""]
    excludedIds: ["asst_excludedAssistantId"]

  bedrock:
    availableRegions:
      - "us-west-2"
      - "us-east-1"
    streamRate: 35
    titleModel: 'anthropic.claude-3-haiku-20240307-v1:0'

  custom:
    # groq
    # Model list: https://console.groq.com/settings/limits
    - name: "groq"
      apiKey: "${GROQ_API_KEY}"
      baseURL: "https://api.groq.com/openai/v1/"
      models:
        default:
          [
            "llama-3.3-70b-versatile",
            "llama-3.1-405b-reasoning",
            "llama-3.1-70b-versatile",
            "llama-3.1-8b-instant",
            "llama3-groq-70b-8192-tool-use-preview",
            "llama3-groq-8b-8192-tool-use-preview",
            "llama3-70b-8192",
            "llama3-8b-8192",
            "mixtral-8x7b-32768",
            "gemma-7b-it",
            "gemma2-9b-it",
            "deepseek-r1-distill-llama-70b",
            "llama-3.2-1b-preview",
            "llama-3.2-3b-preview"
          ]
        fetch: false
      titleConvo: true
      titleModel: "mixtral-8x7b-32768"
      modelDisplayLabel: "groq"

    # Mistral AI API
    - name: "Mistral"
      apiKey: "${MISTRAL_API_KEY}"
      baseURL: "https://api.mistral.ai/v1"
      models:
        default:
          [
            "mistral-tiny",
            "mistral-small",
            "mistral-medium",
            "mistral-large-latest",
          ]
        fetch: false
      titleConvo: true
      titleMethod: "completion"
      titleModel: "mistral-tiny"
      summarize: false
      summaryModel: "mistral-tiny"
      forcePrompt: false
      modelDisplayLabel: "Mistral"
      dropParams: ["stop", "user", "frequency_penalty", "presence_penalty"]

    # OpenRouter.ai
    - name: "OpenRouter"
      apiKey: "${OPENROUTER_KEY}"
      baseURL: "https://openrouter.ai/api/v1"
      models:
        "default":
          [
            "openrouter/auto",
            "---FREE---",
            "google/gemma-7b-it:free",
            "gryphe/mythomist-7b:free",
            "huggingfaceh4/zephyr-7b-beta:free",
            "meta-llama/llama-3-8b-instruct:free",
            "microsoft/phi-3-medium-128k-instruct:free",
            "microsoft/phi-3-mini-128k-instruct:free",
            "mistralai/mistral-7b-instruct:free",
            "nousresearch/nous-capybara-7b:free",
            "openchat/openchat-7b:free",
            "openrouter/cinematika-7b:free",
            "undi95/toppy-m-7b:free",
            "---NITRO---",
            "google/gemma-7b-it:nitro",
            "gryphe/mythomax-l2-13b:nitro",
            "meta-llama/llama-2-70b-chat:nitro",
            "meta-llama/llama-3-70b-instruct:nitro",
            "meta-llama/llama-3-8b-instruct:nitro",
            "mistralai/mistral-7b-instruct:nitro",
            "mistralai/mixtral-8x7b-instruct:nitro",
            "undi95/toppy-m-7b:nitro",
            "---BETA---",
            "anthropic/claude-2.0:beta",
            "anthropic/claude-2.1:beta",
            "anthropic/claude-2:beta",
            "anthropic/claude-3-haiku:beta",
            "anthropic/claude-3-opus:beta",
            "anthropic/claude-3-sonnet:beta",
            "anthropic/claude-instant-1:beta",
            "---EXTENDED---",
            "gryphe/mythomax-l2-13b:extended",
            "meta-llama/llama-3-8b-instruct:extended",
            "neversleep/llama-3-lumimaid-8b:extended",
            "undi95/remm-slerp-l2-13b:extended",
            "---01-AI---",
            "01-ai/yi-34b",
            "01-ai/yi-34b-chat",
            "01-ai/yi-6b",
            "---ANTHROPIC---",
            "anthropic/claude-1",
            "anthropic/claude-1.2",
            "anthropic/claude-2",
            "anthropic/claude-2.0",
            "anthropic/claude-2.1",
            "anthropic/claude-3-haiku",
            "anthropic/claude-3-opus",
            "anthropic/claude-3-sonnet",
            "anthropic/claude-instant-1",
            "anthropic/claude-instant-1.0",
            "anthropic/claude-instant-1.1",
            "---COHERE---",
            "cohere/command",
            "cohere/command-r",
            "cohere/command-r-plus",
            "---GOOGLE---",
            "google/gemini-flash-1.5",
            "google/gemini-pro",
            "google/gemini-pro-1.5",
            "google/gemini-pro-vision",
            "google/gemma-7b-it",
            "google/palm-2-chat-bison",
            "google/palm-2-chat-bison-32k",
            "google/palm-2-codechat-bison",
            "google/palm-2-codechat-bison-32k",
            "---META-LLAMA---",
            "meta-llama/codellama-34b-instruct",
            "meta-llama/llama-2-13b-chat",
            "meta-llama/llama-2-70b-chat",
            "meta-llama/llama-3-70b",
            "meta-llama/llama-3-70b-instruct",
            "meta-llama/llama-3-8b",
            "meta-llama/llama-3-8b-instruct",
            "meta-llama/llama-guard-2-8b",
            "---MICROSOFT---",
            "microsoft/phi-3-medium-128k-instruct",
            "microsoft/phi-3-mini-128k-instruct",
            "microsoft/wizardlm-2-7b",
            "microsoft/wizardlm-2-8x22b",
            "---MISTRALAI---",
            "mistralai/mistral-7b-instruct",
            "mistralai/mistral-7b-instruct-v0.1",
            "mistralai/mistral-7b-instruct-v0.2",
            "mistralai/mistral-7b-instruct-v0.3",
            "mistralai/mistral-large",
            "mistralai/mistral-medium",
            "mistralai/mistral-small",
            "mistralai/mistral-tiny",
            "mistralai/mixtral-8x22b",
            "mistralai/mixtral-8x22b-instruct",
            "mistralai/mixtral-8x7b",
            "mistralai/mixtral-8x7b-instruct",
            "---NEVERSLEEP---",
            "neversleep/llama-3-lumimaid-70b",
            "neversleep/llama-3-lumimaid-8b",
            "neversleep/noromaid-20b",
            "neversleep/noromaid-mixtral-8x7b-instruct",
            "---NOUSRESEARCH---",
            "nousresearch/hermes-2-pro-llama-3-8b",
            "nousresearch/nous-capybara-34b",
            "nousresearch/nous-capybara-7b",
            "nousresearch/nous-hermes-2-mistral-7b-dpo",
            "nousresearch/nous-hermes-2-mixtral-8x7b-dpo",
            "nousresearch/nous-hermes-2-mixtral-8x7b-sft",
            "nousresearch/nous-hermes-2-vision-7b",
            "nousresearch/nous-hermes-llama2-13b",
            "nousresearch/nous-hermes-yi-34b",
            "---OPENAI---",
            "openai/gpt-3.5-turbo",
            "openai/gpt-3.5-turbo-0125",
            "openai/gpt-3.5-turbo-0301",
            "openai/gpt-3.5-turbo-0613",
            "openai/gpt-3.5-turbo-1106",
            "openai/gpt-3.5-turbo-16k",
            "openai/gpt-3.5-turbo-instruct",
            "openai/gpt-4",
            "openai/gpt-4-0314",
            "openai/gpt-4-1106-preview",
            "openai/gpt-4-32k",
            "openai/gpt-4-32k-0314",
            "openai/gpt-4-turbo",
            "openai/gpt-4-turbo-preview",
            "openai/gpt-4-vision-preview",
            "openai/gpt-4o",
            "openai/gpt-4o-2024-05-13",
            "---PERPLEXITY---",
            "perplexity/llama-3-sonar-large-32k-chat",
            "perplexity/llama-3-sonar-large-32k-online",
            "perplexity/llama-3-sonar-small-32k-chat",
            "perplexity/llama-3-sonar-small-32k-online",
            "---QWEN---",
            "qwen/qwen-110b-chat",
            "qwen/qwen-14b-chat",
            "qwen/qwen-32b-chat",
            "qwen/qwen-4b-chat",
            "qwen/qwen-72b-chat",
            "qwen/qwen-7b-chat",
            "---OTHERS---",
            "allenai/olmo-7b-instruct",
            "alpindale/goliath-120b",
            "austism/chronos-hermes-13b",
            "codellama/codellama-70b-instruct",
            "cognitivecomputations/dolphin-mixtral-8x7b",
            "databricks/dbrx-instruct",
            "deepseek/deepseek-chat",
            "deepseek/deepseek-coder",
            "fireworks/firellava-13b",
            "gryphe/mythomax-l2-13b",
            "gryphe/mythomist-7b",
            "huggingfaceh4/zephyr-7b-beta",
            "intel/neural-chat-7b",
            "jebcarter/psyfighter-13b",
            "jondurbin/airoboros-l2-70b",
            "jondurbin/bagel-34b",
            "koboldai/psyfighter-13b-2",
            "liuhaotian/llava-13b",
            "liuhaotian/llava-yi-34b",
            "lizpreciatior/lzlv-70b-fp16-hf",
            "lynn/soliloquy-l3",
            "mancer/weaver",
            "open-orca/mistral-7b-openorca",
            "openchat/openchat-7b",
            "openrouter/cinematika-7b",
            "phind/phind-codellama-34b",
            "pygmalionai/mythalion-13b",
            "recursal/eagle-7b",
            "recursal/rwkv-5-3b-ai-town",
            "rwkv/rwkv-5-world-3b",
            "sao10k/fimbulvetr-11b-v2",
            "snowflake/snowflake-arctic-instruct",
            "sophosympatheia/midnight-rose-70b",
            "teknium/openhermes-2-mistral-7b",
            "teknium/openhermes-2.5-mistral-7b",
            "togethercomputer/stripedhyena-hessian-7b",
            "togethercomputer/stripedhyena-nous-7b",
            "undi95/remm-slerp-l2-13b",
            "undi95/toppy-m-7b",
            "xwin-lm/xwin-lm-70b",
          ]
        fetch: false
      dropParams: ["stop"]
      titleConvo: true
      titleModel: "gpt-3.5-turbo"
      summarize: false
      summaryModel: "gpt-3.5-turbo"
      forcePrompt: false
      modelDisplayLabel: "OpenRouter"

    # Preplexity
    # Model list: https://docs.perplexity.ai/docs/model-cards
    - name: "Perplexity"
      apiKey: "${PERPLEXITY_API_KEY}"
      baseURL: "https://api.perplexity.ai/"
      models:
        default:
          [
            "llama-3.1-sonar-small-128k-chat",
            "llama-3.1-sonar-small-128k-online",
            "llama-3.1-sonar-large-128k-chat",
            "llama-3.1-sonar-large-128k-online",
            "llama-3.1-sonar-huge-128k-online",
            "llama-3.1-8b-instruct",
            "llama-3.1-70b-instruct",
          ]
        fetch: false # fetching list of models is not supported
      titleConvo: true
      titleModel: "llama-3.1-sonar-small-128k-chat"
      summarize: false
      summaryModel: "llama-3.1-sonar-small-128k-chat"
      forcePrompt: false
      dropParams: ["stop", "frequency_penalty"]
      modelDisplayLabel: "Perplexity"

    # deepseek
    # https://platform.deepseek.com/api_keys
    # Model list: https://platform.deepseek.com/api-docs/pricing
    - name: "deepseek"
      apiKey: "${DEEPSEEK_API_KEY}"
      baseURL: "https://api.deepseek.com"
      models:
        default: ["deepseek-chat", "deepseek-coder"]
        fetch: false
      titleConvo: true
      titleModel: "deepseek-chat"
      summarize: false
      summaryModel: "deepseek-chat"
      forcePrompt: false
      modelDisplayLabel: "DeepSeek"

    # Fireworks.ai
    # Models: https://fireworks.ai/models?show=Serverless
    - name: "Fireworks"
      apiKey: "${FIREWORKS_API_KEY}"
      baseURL: "https://api.fireworks.ai/inference/v1"
      models:
        default:
          [
            "accounts/fireworks/models/devashisht-test-v2",
            "accounts/fireworks/models/dt-fc-rc-v1",
            "accounts/fireworks/models/firefunction-v1",
            "accounts/fireworks/models/firefunction-v2",
            "accounts/fireworks/models/firellava-13b",
            "accounts/devashisht-72fdad/models/function-calling-v11",
            "accounts/fireworks/models/fw-function-call-34b-v0",
            "accounts/stability/models/japanese-stablelm-instruct-beta-70b",
            "accounts/stability/models/japanese-stablelm-instruct-gamma-7b",
            "accounts/fireworks/models/japanese-stable-vlm",
            "accounts/fireworks/models/gemma2-9b-it",
            "accounts/fireworks/models/llama-v3p1-405b-instruct",
            "accounts/fireworks/models/llama-v3p1-70b-instruct",
            "accounts/fireworks/models/llama-v3p1-8b-instruct",
            "accounts/fireworks/models/llama-v3-70b-instruct",
            "accounts/fireworks/models/llama-v3-70b-instruct-hf",
            "accounts/fireworks/models/llama-v3-8b-hf",
            "accounts/fireworks/models/llama-v3-8b-instruct",
            "accounts/fireworks/models/llama-v3-8b-instruct-hf",
            "accounts/fireworks/models/llama-v2-13b-chat",
            "accounts/fireworks/models/llama-v2-13b-code-instruct",
            "accounts/fireworks/models/llama-v2-34b-code-instruct",
            "accounts/fireworks/models/llama-v2-70b-chat",
            "accounts/fireworks/models/llama-v2-70b-code-instruct",
            "accounts/fireworks/models/llama-v2-7b-chat",
            "accounts/fireworks/models/deepseek-coder-v2-instruct",
            "accounts/fireworks/models/deepseek-coder-v2-lite-instruct",
            "accounts/fireworks/models/llava-v15-13b-fireworks",
            "accounts/fireworks/models/mistral-7b-instruct-4k",
            "accounts/dev-e24710/models/mistral-spellbound-format",
            "accounts/fireworks/models/mixtral-8x22b-instruct",
            "accounts/fireworks/models/mixtral-8x7b-instruct",
            "accounts/fireworks/models/mixtral-8x7b-instruct-hf",
            "accounts/fireworks/models/new-mixtral-chat",
            "accounts/fireworks/models/qwen-14b-chat",
            "accounts/fireworks/models/qwen-1-8b-chat",
            "accounts/fireworks/models/qwen-72b-chat",
            "accounts/stability/models/stablelm-zephyr-3b",
            "accounts/fireworks/models/yi-34b-200k-capybara",
          ]
        fetch: false
      titleConvo: true
      titleModel: "accounts/fireworks/models/llama-v2-7b-chat"
      summarize: false
      summaryModel: "accounts/fireworks/models/llama-v2-7b-chat"
      forcePrompt: false
      modelDisplayLabel: "Fireworks"
      dropParams: ["user"]
